{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4baa77",
   "metadata": {},
   "source": [
    "# 1. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c5df2",
   "metadata": {},
   "source": [
    "#### In this assignment, you are expected to practice building pipeline, doing k-fold cross validation and performing hyperparameter tuning.\n",
    "#### You will be working with mobile phone dataset (mobile_train.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dfa930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('mobile_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a97c8",
   "metadata": {},
   "source": [
    "# 2. Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8df7f9",
   "metadata": {},
   "source": [
    "#### Build a random forest classifier model and perform hyperparameter tuning using grid search. Also apply 5-fold cross validation while doing searching. Use following values for the search:\n",
    "- n_estimators - 100, 200, 300\n",
    "- max_depth - 3, 5\n",
    "- criterion - gini, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1703e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100 3 gini': 0.817, '100 3 entropy': 0.7955, '100 5 gini': 0.8460000000000001, '100 5 entropy': 0.851, '200 3 gini': 0.8085000000000001, '200 3 entropy': 0.796, '200 5 gini': 0.853, '200 5 entropy': 0.8525, '300 3 gini': 0.8105, '300 3 entropy': 0.8035, '300 5 gini': 0.851, '300 5 entropy': 0.8515}\n",
      "\n",
      "\n",
      "Best params:  200 5 gini\n"
     ]
    }
   ],
   "source": [
    "# manually searching using for loops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "X=df[['battery_power','int_memory','ram','n_cores','px_height','px_width','three_g','wifi']]  # Features\n",
    "y=df['price_range']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "n_estimators=[100,200,300]\n",
    "max_depths=[3,5]\n",
    "criterions=['gini', 'entropy']\n",
    "\n",
    "avg_scores={}\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    for max_depth in max_depths:\n",
    "        for criterion in criterions:\n",
    "            clf=RandomForestClassifier(n_estimators=n_estimator,max_depth=max_depth, criterion=criterion)\n",
    "            scores=cross_val_score(clf,X,y,cv=5)\n",
    "            avg_scores[str(n_estimator)+' '+str(max_depth)+' '+criterion] = np.average(scores)\n",
    "\n",
    "print(avg_scores)\n",
    "print('\\n\\nBest params: ', list(avg_scores.keys())[list(avg_scores.values()).index(max(avg_scores.values()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46ea153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.298204</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.026540</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'n_estim...</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.802500</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.596722</td>\n",
       "      <td>0.034765</td>\n",
       "      <td>0.048322</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'n_estim...</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.800625</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885575</td>\n",
       "      <td>0.024677</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'n_estim...</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328341</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.024226</td>\n",
       "      <td>0.010356</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671200</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.044598</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973848</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.070015</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.340063</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.025402</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.784375</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.799375</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.690679</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>0.045941</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.801250</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.074413</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.066001</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'n_es...</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.452838</td>\n",
       "      <td>0.048386</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.853750</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.891265</td>\n",
       "      <td>0.016420</td>\n",
       "      <td>0.049231</td>\n",
       "      <td>0.007883</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.840625</td>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.850625</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.324449</td>\n",
       "      <td>0.040889</td>\n",
       "      <td>0.074807</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.854375</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.298204      0.007540         0.026540        0.008772   \n",
       "1        0.596722      0.034765         0.048322        0.001346   \n",
       "2        0.885575      0.024677         0.071761        0.007334   \n",
       "3        0.328341      0.006573         0.024226        0.010356   \n",
       "4        0.671200      0.019518         0.044598        0.006041   \n",
       "5        0.973848      0.006605         0.070015        0.007736   \n",
       "6        0.340063      0.004943         0.025402        0.007570   \n",
       "7        0.690679      0.017630         0.045941        0.007763   \n",
       "8        1.074413      0.044907         0.066001        0.003526   \n",
       "9        0.452838      0.048386         0.024354        0.004083   \n",
       "10       0.891265      0.016420         0.049231        0.007883   \n",
       "11       1.324449      0.040889         0.074807        0.005458   \n",
       "\n",
       "   param_criterion param_max_depth param_n_estimators  \\\n",
       "0             gini               3                100   \n",
       "1             gini               3                200   \n",
       "2             gini               3                300   \n",
       "3             gini               5                100   \n",
       "4             gini               5                200   \n",
       "5             gini               5                300   \n",
       "6          entropy               3                100   \n",
       "7          entropy               3                200   \n",
       "8          entropy               3                300   \n",
       "9          entropy               5                100   \n",
       "10         entropy               5                200   \n",
       "11         entropy               5                300   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.806250   \n",
       "1   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.815625   \n",
       "2   {'criterion': 'gini', 'max_depth': 3, 'n_estim...           0.815625   \n",
       "3   {'criterion': 'gini', 'max_depth': 5, 'n_estim...           0.853125   \n",
       "4   {'criterion': 'gini', 'max_depth': 5, 'n_estim...           0.865625   \n",
       "5   {'criterion': 'gini', 'max_depth': 5, 'n_estim...           0.862500   \n",
       "6   {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.793750   \n",
       "7   {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.825000   \n",
       "8   {'criterion': 'entropy', 'max_depth': 3, 'n_es...           0.825000   \n",
       "9   {'criterion': 'entropy', 'max_depth': 5, 'n_es...           0.871875   \n",
       "10  {'criterion': 'entropy', 'max_depth': 5, 'n_es...           0.859375   \n",
       "11  {'criterion': 'entropy', 'max_depth': 5, 'n_es...           0.862500   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.812500           0.806250           0.806250   \n",
       "1            0.793750           0.790625           0.825000   \n",
       "2            0.790625           0.790625           0.809375   \n",
       "3            0.843750           0.853125           0.865625   \n",
       "4            0.837500           0.862500           0.862500   \n",
       "5            0.828125           0.856250           0.865625   \n",
       "6            0.809375           0.784375           0.828125   \n",
       "7            0.800000           0.790625           0.818750   \n",
       "8            0.787500           0.790625           0.834375   \n",
       "9            0.837500           0.853125           0.859375   \n",
       "10           0.840625           0.840625           0.865625   \n",
       "11           0.850000           0.843750           0.862500   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.781250         0.802500        0.010897                8  \n",
       "1            0.778125         0.800625        0.017162               10  \n",
       "2            0.793750         0.800000        0.010458               11  \n",
       "3            0.850000         0.853125        0.007126                5  \n",
       "4            0.846875         0.855000        0.010933                2  \n",
       "5            0.868750         0.856250        0.014658                1  \n",
       "6            0.781250         0.799375        0.017388               12  \n",
       "7            0.771875         0.801250        0.019223                9  \n",
       "8            0.787500         0.805000        0.020406                7  \n",
       "9            0.846875         0.853750        0.011592                4  \n",
       "10           0.846875         0.850625        0.010155                6  \n",
       "11           0.853125         0.854375        0.007289                3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using GRID SEARCH \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "clf = GridSearchCV(model, {\n",
    "    'n_estimators':[100,200,300],\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[3,5]\n",
    "}, cv=5, return_train_score=False)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "grid_search_results = pd.DataFrame(clf.cv_results_)\n",
    "grid_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e314c2",
   "metadata": {},
   "source": [
    "#### Get the best score and optimal values for hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491b08a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 5, 'n_estimators': 300}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36eb52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3740c7",
   "metadata": {},
   "source": [
    "#### Perform hyperparameter tuning using random search. Increase number of iterations if needed. Do not forget about 5-fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22fd3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 12 is smaller than n_iter=500. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8571666666666667\n",
      "Best Hyperparameters: {'n_estimators': 300, 'max_depth': 5, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = [100, 200, 300] \n",
    "space['criterion'] = ['gini', 'entropy']\n",
    "space['max_depth'] = [3, 5]\n",
    "\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "result = search.fit(X, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97565fc",
   "metadata": {},
   "source": [
    "#### Create a pipeline and add standard scaling and dimensionality reduction. You can use StandardScaler and PCA. Perform tuning by random search. Now you have to provide values for hyperparameters of different components of your pipeline. Find out how you can achieve that. For PCA, one hyperparameter to tune would be number of components. Try to isolate and check the effect of scaling and dimensionality reduction on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2657943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65d5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=2)),\n",
    "                     ('lr_classifier',LogisticRegression(random_state=0))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb4c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
    "                     ('pca2',PCA(n_components=2)),\n",
    "                     ('dt_classifier',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b15f72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
    "                     ('pca3',PCA(n_components=2)),\n",
    "                     ('rf_classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ad36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LEts make the list of pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b691fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e8829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98dbb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "\tpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d22eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.385\n",
      "Decision Tree Test Accuracy: 0.355\n",
      "RandomForest Test Accuracy: 0.3725\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b1e63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy:Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(X_test,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "156845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0029c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 330.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.548125      nan 0.546875      nan 0.54125       nan 0.55          nan\n",
      " 0.54875       nan 0.546875      nan 0.5475        nan 0.54875       nan\n",
      " 0.548125      nan 0.545625      nan 0.95375  0.53375  0.5375   0.76375\n",
      " 0.954375 0.534375 0.5375   0.79     0.955625 0.53375  0.5375   0.815\n",
      " 0.950625 0.53375  0.5375   0.8275   0.9525   0.53375  0.5375   0.815625\n",
      " 0.9525   0.534375 0.5375   0.818125 0.955625 0.53375  0.5375   0.815625\n",
      " 0.955    0.53375  0.5375   0.815    0.95125  0.53375  0.5375   0.8225\n",
      " 0.954375 0.534375 0.5375   0.81875  0.79875  0.8075   0.805    0.8475\n",
      " 0.856875 0.8625  ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier',\n",
      "                 LogisticRegression(C=7.742636826811269, solver='newton-cg'))])\n",
      "The mean accuracy of the model is: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bashi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2','l1'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                 },\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 },\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [100, 200, 300],\n",
    "                 \"classifier__max_depth\":[3, 5]}]\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "\n",
    "print(best_model.best_estimator_)\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54e0cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7465e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipe = make_pipeline((RandomForestClassifier()))\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "                {\"randomforestclassifier\": [RandomForestClassifier()],\n",
    "                 \"randomforestclassifier__n_estimators\": [100, 200, 300],\n",
    "                 \"randomforestclassifier__max_depth\":[3, 5]}]\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0016bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a90bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
